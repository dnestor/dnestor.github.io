[
  {
    "path": "posts/2022-02-05-text1/",
    "title": "Text as Data Post 1",
    "description": "General outline of my proposed research topic with analysis on feasability and a brief literature review.",
    "author": [
      {
        "name": "Dana Nestor",
        "url": "https://dnestor.github.io/"
      }
    ],
    "date": "2022-02-05",
    "categories": [],
    "contents": "\nResearch Questions\nBackground\nManagement rights clauses are used to strategically reserve certain bargaining positions allowing “exclusive rights to manage, to direct…employees; to evaluate performance, to discipline and discharge employees, to adopt and enforce rules and regulations and policies.” Aided by friendly judicial decisions, these clauses are often beyond reach of the National Labor Relations Board (NLRB) and lower court review.\nBy claiming certain rights and bargaining to impasse, management is able to immediately implement their last best offer at the expiration of a collective bargaining agreement (CBA). Fighting this is a time consuming and expensive proposition, making this a significant point of leverage in contract negotiations.\nAdditionally, courts have relied on empirical analyses of the use of management rights clauses in some of their foundational decisions on this topic (see NLRB v. American National Insurance Co., 343 U.S. 395 (1952)). This opens the door for further analysis to not only improve understanding of the use and spread of these clauses, but even to introduce new evidence that may sway the judiciary towards a new view of the legitimacy of the practice.\nPotential Avenues of Exploration\nMap proliferation of specific clauses: how have these clauses spread? Is there a distinguishable network that we can identify from the data?\nHarness metadata of CBAs to create networks, attach directionality and weights based on identified management rights features to identify probabilities that specific clauses or contract language disseminated via a network or by chance.\n\nQuantify evolution of clauses: how has the language changed? Can we identify specific trends by sector, industry, size of organization, etc.?\nUse statistical analysis (machine learning classification models) to quantify the probability that a clause is related to management rights, combine with content/thematic analysis and/or critical discourse analysis to quantify these changes.\nEstablish supervised scaling approach to identify potential latent dimensions of the text and any correlations to networks, industries, etc.\n\nCompare against history: can we see correlations between changes in language or speed of proliferation against major milestones in the development of labor law and/or union strategy?\nData Sources\nCBA data is available online for contracts dating all the way back to 1935, 12 years before the Taft-Hartley amendment mandated centralized record keeping. The U.S. Department of Labor Office of Labor-Management Standards (DOL-OLMS) maintains mostly current (though also some historical) records both online and as a Microsoft Access database, including metadata on the bargaining parties, contract dates, employee counts, industry, and links to PDF copies of the full CBA. This dataset is inclusive of both public and private sector CBAs. As of February 5th, 2022, the DOL-OLMS database contained 3,730 entries.\nAdditionally, Cornell University’s School of Industrial and Labor Relations, Catherwood Library, maintains a historical database on behalf of DOL-OLMS. This is where most pre-1990 CBAs can be found, and it contains similar information to the DOL-OLMS database in terms of metadata and full CBAs. While Cornell is in the process of fully converting those files into machine-readable format, it is unclear what percentage of the collection is currently in this form - this could present a significant issue in data collection. That said, the data set currently contains 2,834 documents dating back to 1935.\nFinally, the University of California Berkeley’s Institute for Research on Labor and Employment maintains a fully-text-recognized database of union contracts from around the world. However, this data set is the smallest of the three and contains mostly public sector agreements, which differ substantially from the private sector when it comes to management rights clauses due to structural differences in the industry and laws governing these contracts. This database likely will not benefit the project.\nLiterature Review\nAsh, E., MacLeod, W. B., & Naidu, S. (n.d.-a). Optimal Contract Design in the Wild: Rigidity and Control in Collective Bargaining. 46.\nAnalysis of a corpus of 30,000 collective bargaining agreements from Canada from 1986 through 2015. Using ideas and methods from computational linguistics, authors extract measures of rigidity and worker control from the text of the contract clauses. They then analyze how rigidity and authority in contracts varies according to firm-level factors and external factors. This could be used to identify and externally validate the core methodology of this project.\n\nAsh, E., MacLeod, W. B., & Naidu, S. (n.d.-b). The Language of Contract: Promises and Power in Union Collective Bargaining Agreements. 59.\nSame authors and data as previous entry\n\nRosen, S. Z. (n.d.). Marceau, Drafting a Union Contract. Case Western Reserve Law Review, 6.\nThis handbook provides a perspective on the procedure of drafting a union contract in the 1960s. It could be helpful in identifying changes to procedure over time.\n\nWard, M. N. (2004). Contracting participation out of union culture: Patterns of modality and interactional moves in a labour contract settlement / Maurice Norman Ward. [Thesis, The University of Adelaide]. https://digital.library.adelaide.edu.au/dspace/handle/2440/22342\nThis doctoral thesis uses Systemic Functional Linguistics, Critical Discourse Analysis, qualitative, and computational analysis to investigate how language and power interact to construct relationships in the union setting and whether or not union discourse structures promote member participation. While it concentrates on only four documents, the methodologies described here could be useful for latent dimension identification and analysis.\n\n",
    "preview": {},
    "last_modified": "2022-02-05T14:42:17-05:00",
    "input_file": "text1.knit.md"
  },
  {
    "path": "posts/2022-02-02-networks2/",
    "title": "Short Assignment 2",
    "description": "Short assignment 2 for Political and Social Network Analysis",
    "author": [
      {
        "name": "Dana Nestor",
        "url": "https://dnestor.github.io/"
      }
    ],
    "date": "2022-02-02",
    "categories": [],
    "contents": "\nUtilizing the provided bill cosponsorship data from the 112th congress and (modified) related import scripts, I read-in a CSV file and built both igraph and statnet objects to commence investigation. This data contains unique identifiers for each Member, the bill number, the date the Member joined in cosponsorship (and left, if applicable) and whether or not the member was an original co-sponsor.\n\n\ndata <- read_csv(\"~/DACSS/Network Analysis/govtrack_cosponsor_data_112_congress.csv\")\n\n# Provided script, modified so it would work with the available data\n nodes <- data[c(\"name\",\"thomas_id\",\"bioguide_id\",\"state\",\"district\")]\n  nodes <- distinct(nodes, name, state, bioguide_id, thomas_id, .keep_all = TRUE)\n  \n  #There are repeat entries for congress people who are given both a thomas_id (old system) and a\n  #bioguide_id (new system). Lets fix this by splitting and merging. \n    nodes_a  <- nodes[is.na(nodes$thomas_id),]\n    nodes_a  <- nodes[c(\"name\",\"state\",\"district\",\"bioguide_id\")]\n    nodes_b  <- nodes[is.na(nodes$bioguide_id),]\n    nodes_b  <- nodes[c(\"name\",\"state\",\"district\",\"thomas_id\")]\n    nodes    <- merge(x = nodes_a, y = nodes_b, by = c(\"name\",\"state\",\"district\"), all = TRUE)\n    rm(nodes_a);rm(nodes_b)\n  \n  #Lets also create a new ID that will be assigned to all congress people\n    nodes$ID <- 1:nrow(nodes)\n  \n  #Lets reorder the data putting the ID first\n    nodes <- nodes[c(\"ID\",\"name\",\"state\",\"district\",\"bioguide_id\",\"thomas_id\")]\n  \n#Now let's create a dataframe that contains just edge atributes\n  #Lets add the from_id collumn, replacing all the node attributes given for the senator cosponsoring\n    edge_list <- data\n    edge_list$node_1[!is.na(edge_list$thomas_id)]    <- nodes$ID[match(edge_list$thomas_id, nodes$thomas_id)][!is.na(edge_list$thomas_id)]\n    edge_list$node_1[!is.na(edge_list$bioguide_id)]  <- nodes$ID[match(edge_list$bioguide_id, nodes$bioguide_id)][!is.na(edge_list$bioguide_id)]\n    edge_list <- edge_list[c(\"node_1\",\"bill_number\",\"original_cosponsor\",\"date_signed\",\"date_withdrawn\",\"sponsor\")]\n  \n  #At this point, the \"edges\" dataframe contains links between sponsors and bills. Instead we want want \n  #the edgelist to represent to links between legislators. \n  #Let's do that by replacing the bill number collumn with the ID of the bill's original sponsor\n    sponsor_key    <- edge_list[edge_list$sponsor == TRUE, c(\"node_1\",\"bill_number\")]\n    edge_list$node_2   <- sponsor_key$node_1[match(edge_list$bill_number, sponsor_key$bill_number)]\n    \n  #Lets reorder the dataframe, putting the edgelist in the first two collumns\n      edge_list <- edge_list[c('node_1', 'node_2', 'bill_number','sponsor', 'original_cosponsor', 'date_signed', 'date_withdrawn')]\n    \n  #We dont need to keep the looped connections that represent legislators sponsoring their own bills\n      edge_list <- edge_list[edge_list$sponsor == FALSE,]\n  \n  #We can now remove the sponsor collum\n      edge_list <- edge_list[c('node_1', 'node_2', 'bill_number','original_cosponsor', 'date_signed', 'date_withdrawn')]\n      \n  #And remove unessesary objects\n      rm(sponsor_key)\n\n#Now let's make an igraph object\n  network_igraph <- graph_from_data_frame(d = edge_list, directed = TRUE, vertices = nodes)\n  \n#Now lets create a statnet object\n  \n  network_statnet <- network(as.matrix(edge_list[1:2]), matrix.type = \"edgelist\", directed = TRUE)\n  \n  network_statnet%e%'bill_number'         <- as.character(edge_list$bill_number)\n  network_statnet%e%'original_cosponsor'  <- as.character(edge_list$original_cosponsor)\n  network_statnet%e%'date_signed'         <- as.character(edge_list$date_signed)\n  network_statnet%e%'date_withdrawn'      <- as.character(edge_list$date_withdrawn)\n  \n  network_statnet%v%'name'        <-as.character(nodes$name[match(nodes$ID,network_statnet%v%'vertex.names')])\n  network_statnet%v%'state'       <-as.character(nodes$state[match(nodes$ID,network_statnet%v%'vertex.names')])\n  network_statnet%v%'district'    <-as.character(nodes$district[match(nodes$ID,network_statnet%v%'vertex.names')])\n  network_statnet%v%'bioguide_id' <-as.character(nodes$bioguide_id[match(nodes$ID,network_statnet%v%'vertex.names')])\n  network_statnet%v%'thomas_id'   <-as.character(nodes$thomas_id[match(nodes$ID,network_statnet%v%'vertex.names')])\n  \n\n#Lets create properly named objects and delete unessesary ones\n  network_nodes <- nodes\n  network_edgelist <- edge_list\n  rm(nodes);rm(data);rm(edge_list)\n\n\n\nIn further examining the data, we can see that there are 550 vertices and 1.32863^{5} edges in the igraph network. Additional features include:\nFeature\nT/F?\nBipartite\nFALSE\nDirected\nTRUE\nWeighted\nFALSE\nComparing the igraph object to the statnet object, we can see that the same network features hold true.\nWe can now take a dyad census to get an initial understanding of the connections in our network.\n\n\nigraph::dyad.census(network_igraph)\n\n\n$mut\n[1] 26734\n\n$asym\n[1] 79395\n\n$null\n[1] 44846\n\nsna::dyad.census(network_statnet)\n\n\n       Mut  Asym  Null\n[1,] 16388 35138 99449\n\nFor some reason, the two network objects are returning different measurements with respect to the number of dyad types. This will require further exploration at a later point.\nNext, we examine triads using a census\n\n\nigraph::triad_census(network_igraph)\n\n\n [1] 8427962 5409952 7049451  427375 1236075  731252 1134244  520424\n [9]  673093   36051  245990  472578  271413  243218  507035  191987\n\nsna::triad.census(network_statnet)\n\n\n         003     012     102   021D    021U   021C    111D   111U\n[1,] 8427962 8202667 4256736 427375 1236075 731252 1134244 520424\n       030T  030C    201   120D   120U   120C    210    300\n[1,] 673093 36051 245990 472578 271413 243218 507035 191987\n\nDespite the odd results of the dyad census, the triad census does show identical measurements across the two network object types. To double check that all triads are counted, we can calculate the number of potential triads as (550 * 549 * 548)/6 = 2.75781^{7}. Then, we sum the number of triads in our census sum(igraph::triad_census(network_igraph)) = 2.75781^{7}. The numbers match so we know our function worked correctly.\nFinally, we can look at transitivity within the network to determine the proportion of complete triads in the network.\n\n\ntransitivity(network_igraph)\n\n\n[1] 0.6258881\n\ngtrans(network_statnet)\n\n\n[1] 0.5606059\n\nHere, we see that the transitivity calculatuons differ between the two different network objects. This is likely because the statnet function calculates transitivity slightly differently for directed networks and omits certain triads missing information. However, both functions return a relatively high transitivity score, which makes sense given that this network is specifically intended to involve significant leveraging of connections and wheeling-dealing which requires more transitivity.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-02T21:08:48-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to My Blog",
    "description": "Welcome to my new blog, where I'll be posting assignments from my master's program in data analytics and computational social science",
    "author": [
      {
        "name": "Dana Nestor",
        "url": "https://dnestor.github.io/"
      }
    ],
    "date": "2022-01-29",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-02T21:10:42-05:00",
    "input_file": "welcome.knit.md"
  }
]
